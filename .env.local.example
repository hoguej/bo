# Copy to .env.local and fill in. .env.local is gitignored.

# Dev database (used by daemon locally and by seed:import). Do not use prod here.
DATABASE_URL=

# Prod database URL — one-off use only (e.g. bun run seed:export). Never use for the daemon.
# PROD_DATABASE_URL=

# Your iMessage self-chat handle (required for watch-self and send-self)
BO_MY_PHONE=
# BO_MY_EMAIL=

# Script that receives the message as first arg and prints the agent response to stdout (required for watch-self). Or set config agent_script in admin.
BO_AGENT_SCRIPT=

# Comma-separated numbers: when any of these send a message, we pass it to the agent and reply in that chat
BO_AGENT_NUMBERS=

# Vercel AI Gateway (OpenAI-compatible) auth (recommended)
AI_GATEWAY_API_KEY=

# Optional: which model to use via AI Gateway (default: openai/gpt-4.1)
BO_LLM_MODEL=openai/gpt-4.1

# Optional: default ZIP for weather questions that don't include one
BO_DEFAULT_ZIP=

# Optional: default timezone for calendar/meetings (IANA e.g. America/New_York). Used for "today"/"tomorrow".
# BO_DEFAULT_TZ=America/New_York

# Optional: where bo stores memory (facts). Default: ~/.bo/memory.json
BO_MEMORY_PATH=

# Optional: max conversation messages to keep and send as context (2–100, default 20 ≈ 10 turns)
# BO_CONVERSATION_MESSAGES=20

# Optional: router request/response log file (default ~/.bo/router.log). Set to empty to disable file logging.
# BO_ROUTER_LOG=

# Optional: LLM mock (for tests only). Router uses mock only when BOTH are set. Leave both unset for dev/daemon so the real API is used.
# BO_USE_LLM_MOCK=1
# BO_LLM_MOCK_PATH=/path/to/mock.json

# Optional: Telegram bot token from BotFather. If set, watch-self also runs the Telegram bot in the same process.
# BO_TELEGRAM_BOT_TOKEN=
